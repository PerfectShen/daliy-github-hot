import requests
import feedparser
import os
import time
import hmac
import hashlib
import base64
import re
from bs4 import BeautifulSoup
from datetime import datetime

# ================= é…ç½® =================
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
FEISHU_SECRET = os.getenv("FEISHU_SECRET")
# =======================================

def gen_sign(timestamp, secret):
    string_to_sign = '{}\n{}'.format(timestamp, secret)
    hmac_code = hmac.new(string_to_sign.encode("utf-8"), digestmod=hashlib.sha256).digest()
    sign = base64.b64encode(hmac_code).decode('utf-8')
    return sign

def get_product_hunt():
    """è·å– Product Hunt ä»Šæ—¥æœ€ä½³äº§å“"""
    print("æ­£åœ¨è·å– Product Hunt...")
    url = "https://www.producthunt.com/feed"
    try:
        feed = feedparser.parse(url)
        products = []
        for entry in feed.entries[:5]: # å–å‰5ä¸ª
            title = entry.title
            link = entry.link
            # ç®€çŸ­æè¿°
            desc = entry.summary.split('<br')[0][:100].replace('\n', ' ')
            products.append(f"ğŸš€ **{title}**\n> {desc}\n[æŸ¥çœ‹äº§å“]({link})")
            
        return "**ğŸ¦„ Product Hunt Daily**\n" + "\n\n".join(products)
    except Exception as e:
        print(f"PH Error: {e}")
        return None

def get_weibo_hot():
    """è·å–å¾®åšçƒ­æœ Top 10"""
    print("æ­£åœ¨è·å–å¾®åšçƒ­æœ...")
    url = "https://s.weibo.com/top/summary"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Cookie": "SUB=1" # ç®€å•çš„æ¸¸å®¢ Cookie ç»•è¿‡éªŒè¯
    }
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(resp.text, 'lxml')
        items = soup.select('td.td-02 > a')
        
        hot_list = []
        # è·³è¿‡ç¬¬0ä¸ªï¼ˆé€šå¸¸æ˜¯ç½®é¡¶å¹¿å‘Šï¼‰ï¼Œä»ç¬¬1ä¸ªå¼€å§‹å–
        for i, item in enumerate(items[1:11]): 
            title = item.get_text().strip()
            link = "https://s.weibo.com" + item.get('href')
            # çƒ­åº¦å€¼
            hot_val = item.find_next_sibling('span')
            hot_text = hot_val.get_text().strip() if hot_val else ""
            
            # å‰3ååŠ ç«è‹—å›¾æ ‡
            icon = "ğŸ”¥" if i < 3 else str(i+1) + "."
            
            hot_list.append(f"{icon} [{title}]({link}) `{hot_text}`")
            
        return "**ğŸ‰ å¾®åšçƒ­æœ Top 10**\n" + "\n".join(hot_list)
    except Exception as e:
        print(f"Weibo Error: {e}")
        return None

def get_history_today():
    """
    è·å–å†å²ä¸Šçš„ä»Šå¤© (ç¨³å®šç‰ˆ - æ•°æ®æº: ç™¾åº¦ç™¾ç§‘)
    """
    print("æ­£åœ¨è·å–å†å²ä¸Šçš„ä»Šå¤©...")
    try:
        # 1. è·å–å½“å‰æœˆã€æ—¥
        now = datetime.now()
        month = now.strftime("%m") # ä¾‹å¦‚ "01"
        day = now.strftime("%d")   # ä¾‹å¦‚ "01"
        date_key = month + day     # ä¾‹å¦‚ "0101"

        # 2. è¯·æ±‚ç™¾åº¦ç™¾ç§‘å®˜æ–¹æ¥å£ (æŒ‰æœˆå­˜å‚¨çš„é™æ€JSONï¼Œé€Ÿåº¦å¿«ä¸”ç¨³å®š)
        url = f"https://baike.baidu.com/cms/home/eventsOnHistory/{month}.json"
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        resp = requests.get(url, headers=headers, timeout=5)
        resp.encoding = 'utf-8' # å¼ºåˆ¶ç¼–ç ï¼Œé˜²æ­¢ä¸­æ–‡ä¹±ç 
        all_data = resp.json()
        
        # 3. å®šä½åˆ°â€œä»Šå¤©â€çš„æ•°æ®
        # ç™¾åº¦çš„æ•°æ®ç»“æ„æ˜¯: { "01": { "0101": [ ...events... ] } }
        today_events = all_data.get(month, {}).get(date_key, [])
        
        if not today_events:
            return "**â³ å†å²ä¸Šçš„ä»Šå¤©**\næš‚æ— æ•°æ®"

        # 4. æ¸…æ´—å’Œç­›é€‰æ•°æ®
        # å®šä¹‰ä¸€ä¸ªå»é™¤ HTML æ ‡ç­¾çš„å°å‡½æ•°
        def clean_text(text):
            text = re.sub(r'<.*?>', '', text) # å»æ‰ <a href...> è¿™ç§æ ‡ç­¾
            text = text.replace('&nbsp;', ' ').strip()
            return text

        display_list = []
        # ç™¾åº¦æ•°æ®é€šå¸¸æŒ‰å¹´ä»½æ’åºã€‚
        # ç­–ç•¥ï¼šå–æœ€å 5 æ¡ï¼ˆä¹Ÿå°±æ˜¯ç¦»ç°åœ¨æœ€è¿‘çš„å¹´ä»½ï¼‰ï¼Œæˆ–è€…åè½¬åˆ—è¡¨å–æœ€è‘—åçš„
        # è¿™é‡Œæˆ‘ä»¬å–å€’æ•°5æ¡ï¼Œé€šå¸¸æ˜¯è¿‘ä»£å²ï¼Œå¤§å®¶æ¯”è¾ƒç†Ÿæ‚‰
        for item in today_events[-5:]:
            year = item.get('year')
            title = clean_text(item.get('title'))
            # ç®€å•æ’ç‰ˆ
            display_list.append(f"ğŸ“œ **{year}å¹´**: {title}")
            
        # å†åè½¬ä¸€ä¸‹ï¼Œè®©æœ€è¿‘çš„å¹´ä»½åœ¨æœ€ä¸Šé¢
        display_list.reverse()

        return f"**â³ å†å²ä¸Šçš„ä»Šå¤© ({month}æœˆ{day}æ—¥)**\n" + "\n".join(display_list)

    except Exception as e:
        print(f"History Error: {e}")
        # è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œè¿™æ ·ä½ èƒ½åœ¨é£ä¹¦çœ‹åˆ°æ˜¯å“ªé‡Œé”™äº†ï¼Œè€Œä¸æ˜¯ä»€ä¹ˆéƒ½æ²¡æœ‰
        return f"**â³ å†å²ä¸Šçš„ä»Šå¤©**\næ•°æ®è·å–å¼‚å¸¸: {str(e)[:50]}"

def send_to_feishu(content_list):
    if not FEISHU_WEBHOOK: return
    timestamp = str(int(time.time()))
    sign = gen_sign(timestamp, FEISHU_SECRET)
    
    valid_contents = [c for c in content_list if c]
    if not valid_contents: return

    final_content = "\n\n----------------\n\n".join(valid_contents)
    
    payload = {
        "timestamp": timestamp,
        "sign": sign,
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {"tag": "plain_text", "content": "ğŸŒˆ æ¯æ—¥è¶‹åŠ¿ & çµæ„Ÿ"},
                "template": "orange" # æ©™è‰²ä»£è¡¨æ´»åŠ›
            },
            "elements": [
                {"tag": "markdown", "content": final_content}
            ]
        }
    }
    requests.post(FEISHU_WEBHOOK, json=payload)
    print("æ¨é€æˆåŠŸ")

if __name__ == "__main__":
    msgs = []
    msgs.append(get_weibo_hot())    # åƒç“œ/çƒ­ç‚¹
    msgs.append(get_product_hunt()) # äº§å“çµæ„Ÿ
    msgs.append(get_history_today())# å†å²åº•è•´
    
    send_to_feishu(msgs)